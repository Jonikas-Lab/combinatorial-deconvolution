#! /usr/bin/env python

"""
Basic functions for combinatorial deconvolution of mutant pools, i.e. matching deepseq ___________
 -- Weronika Patena, 2013
"""

# standard library
from __future__ import division
import sys
import unittest
# other packages
# my modules
import binary_code_utilities
import mutant_analysis_classes


# useful stuff: binary_code_utilities.Hamming_distance, binary_code_utilities.bit_change_count (separate 0->1 and 1->0)

def readcounts_to_codewords(joint_dataset, one_cutoff=None, cutoff_per_dataset=None, cutoff_per_mutant=None):
    """ Given a reads-per-mutant dataset and cutoffs, return mutant:sample_name:0/1 dict giving readcounts below/above cutoff.

    Joint_dataset should be a mutant_analysis_classes.Insertional_mutant_pool_dataset instance, multi-dataset.

    There are three ways of specifying readcount cutoffs, and exactly one should be provided:
        - one_cutoff: a single number that will be used for all sample/mutant combinations
        - cutoff_per_dataset: a dataset_name:number dict, so the cutoff depends on the dataset
        - cutoff_per_mutant: a mutant_position:number dict, so the cutoff depends on the mutant
    
    The output is a mutant_position:dataset_name:X nested dictionary, with X 0 if the mutant had <cutoff reads in the dataset, 
     and 1 if it had >=cutoff reads.
    """
    if sum(x is not None for x in (one_cutoff, cutoff_per_dataset, cutoff_per_mutant)) != 1:
        raise ValueError("Must provide exactly one of the cutoff arguments!")
    if one_cutoff is not None:          _get_cutoff = lambda dataset_name, mutant_position: one_cutoff
    if cutoff_per_dataset is not None:  _get_cutoff = lambda dataset_name, mutant_position: cutoff_per_dataset[dataset_name]
    if cutoff_per_mutant is not None:   _get_cutoff = lambda dataset_name, mutant_position: cutoff_per_mutant[mutant_position]
    # TODO there should also be an option with the cutoff depending on BOTH dataset and mutant, somehow... Normalize the per-dataset readcounts before applying the per-mutant cutoff, or something?
    mutant_presence_dict = {}
    for mutant in joint_dataset:
        mutant_presence_dict[mutant.position] = {}
        for dataset_name,dataset_mutant_data in mutant.by_dataset.items():
            if_present = int(bool(dataset_mutant_data.total_read_count >= _get_cutoff(dataset_name, mutant.position)))
            mutant_presence_dict[mutant.position][dataset_name] = if_present
    return mutant_presence_dict


def read_codewords_from_file(infile_name):
    """ Read sample codewords used for combinatorial pooling, from file generated by robotic_plate_transfer.write_data_to_outfile.

    (robotic_plate_transfer is in the ../../combinatorial_pooling/code folder.)

    Return ___
    """
    pass
    # TODO implement!
    # TODO unit-test!


def find_closest_codewords(____):
    """ ___ """
    pass
    # TODO implement!
    # TODO unit-test!


###################################################### Testing ###########################################################

class Testing(unittest.TestCase):
    """ Runs unit-tests for this module. """

    def test__readcounts_to_codewords(self):
        # convenience function for easier output checking:
        def _convert_output(output, datasets, mutants):
            """ Given mutant:datasets:0/1 output dict and lists of datasets and mutants in order, return string like '01 11'. """
            mutant_codewords = {mutant.position: ''.join(str(output[mutant.position][dataset]) for dataset in datasets) 
                                for mutant in mutants}
            return ' '.join([mutant_codewords[mutant.position] for mutant in mutants])
        # make a test case with 3 dataset and 3 mutants: readcounts 0,1,10; 9,20,0; 1,0,3
        datasets = ['A', 'B', 'C']
        pos1 = mutant_analysis_classes.Insertion_position('chr1', '+', position_before=100, immutable=True)
        pos2 = mutant_analysis_classes.Insertion_position('chr2', '-', position_after=501, immutable=True)
        pos3 = mutant_analysis_classes.Insertion_position('chr3', '+', position_before=200, position_after=201, immutable=True)
        mutant1 = mutant_analysis_classes.Insertional_mutant(pos1, multi_dataset=True)
        mutant2 = mutant_analysis_classes.Insertional_mutant(pos2, multi_dataset=True)
        mutant3 = mutant_analysis_classes.Insertional_mutant(pos3, multi_dataset=True)
        mutants = [mutant1, mutant2, mutant3]
        # the three numerical arguments to add_counts are total_reads,perfect_reads,sequence_variants - only the first matters.
        mutant1.add_counts(0, 0, 0, dataset_name=datasets[0])
        mutant1.add_counts(1, 1, 1, dataset_name=datasets[1])
        mutant1.add_counts(10, 10, 1, dataset_name=datasets[2])
        mutant2.add_counts(9, 9, 1, dataset_name=datasets[0])
        mutant2.add_counts(20, 20, 1, dataset_name=datasets[1])
        mutant2.add_counts(0, 0, 0, dataset_name=datasets[2])
        mutant3.add_counts(1, 1, 1, dataset_name=datasets[0])
        mutant3.add_counts(0, 0, 0, dataset_name=datasets[1])
        mutant3.add_counts(3, 3, 1, dataset_name=datasets[2])
        dataset = mutant_analysis_classes.Insertional_mutant_pool_dataset(multi_dataset=True)
        for mutant in mutants:  dataset.add_mutant(mutant)
        # single cutoff (checking all relevant values)
        #   3 mutants: readcounts 0,1,10; 9,20,0; 1,0,3
        assert _convert_output(readcounts_to_codewords(dataset, one_cutoff=0), datasets, mutants)  == '111 111 111'
        assert _convert_output(readcounts_to_codewords(dataset, one_cutoff=1), datasets, mutants)  == '011 110 101'
        assert _convert_output(readcounts_to_codewords(dataset, one_cutoff=2), datasets, mutants)  == '001 110 001'
        assert _convert_output(readcounts_to_codewords(dataset, one_cutoff=3), datasets, mutants)  == '001 110 001'
        assert _convert_output(readcounts_to_codewords(dataset, one_cutoff=4), datasets, mutants)  == '001 110 000'
        assert _convert_output(readcounts_to_codewords(dataset, one_cutoff=9), datasets, mutants)  == '001 110 000'
        assert _convert_output(readcounts_to_codewords(dataset, one_cutoff=10), datasets, mutants) == '001 010 000'
        assert _convert_output(readcounts_to_codewords(dataset, one_cutoff=11), datasets, mutants) == '000 010 000'
        assert _convert_output(readcounts_to_codewords(dataset, one_cutoff=20), datasets, mutants) == '000 010 000'
        assert _convert_output(readcounts_to_codewords(dataset, one_cutoff=21), datasets, mutants) == '000 000 000'
        assert _convert_output(readcounts_to_codewords(dataset, one_cutoff=99), datasets, mutants) == '000 000 000'
        # per-dataset cutoffs
        #   3 mutants: readcounts 0,1,10; 9,20,0; 1,0,3
        _output = lambda CpD: _convert_output(readcounts_to_codewords(dataset, cutoff_per_dataset=CpD), datasets, mutants)
        assert _output({'A':1, 'B':1, 'C':1}) == '011 110 101'
        assert _output({'A':3, 'B':10, 'C':1}) == '001 110 001'
        assert _output({'A':2, 'B':10, 'C':4}) == '001 110 000'
        # per-mutant cutoffs
        #   3 mutants: readcounts 0,1,10; 9,20,0; 1,0,3
        _output = lambda CpM: _convert_output(readcounts_to_codewords(dataset, cutoff_per_mutant=CpM), datasets, mutants)
        assert _output({pos1:1, pos2:1, pos3:1}) ==  '011 110 101'
        assert _output({pos1:2, pos2:2, pos3:1}) ==  '001 110 101'
        assert _output({pos1:2, pos2:2, pos3:4}) ==  '001 110 000'
        assert _output({pos1:2, pos2:10, pos3:4}) == '001 010 000'
        # make sure that it only works with exactly one codeword argument - won't work with 0, any combination of 2, or all 3.
        O, D, M = 1, {'A':1, 'B':1, 'C':1}, {pos1:1, pos2:1, pos3:1}
        self.assertRaises(ValueError, readcounts_to_codewords, dataset)
        self.assertRaises(ValueError, readcounts_to_codewords, dataset, one_cutoff=O, cutoff_per_dataset=D)
        self.assertRaises(ValueError, readcounts_to_codewords, dataset, one_cutoff=O, cutoff_per_mutant=M)
        self.assertRaises(ValueError, readcounts_to_codewords, dataset, cutoff_per_dataset=D, cutoff_per_mutant=M)
        self.assertRaises(ValueError, readcounts_to_codewords, dataset, one_cutoff=O, cutoff_per_dataset=D, cutoff_per_mutant=M)


    # LATER-TODO add more unit-tests!


if __name__=='__main__':
    """ If module is run directly, run tests. """
    print "This is a module for import by other programs - it doesn't do anything on its own.  Running tests..."
    unittest.main()
